{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import collections\n",
    "from metrics_domain_adaptation import utils\n",
    "import json\n",
    "\n",
    "re_langs = re.compile(r\".*/(.{2,2})_(.{2,2})_doc(\\d+)\\.txt\")\n",
    "\n",
    "data_all = collections.defaultdict(dict)\n",
    "for f in glob.glob(\"/home/ec2-user/MetricsDomainAdaptation/data/shuoyang/*_doc*.txt\"):\n",
    "    lang1, lang2, docname = re_langs.match(f).groups()\n",
    "    data_all[(lang1, lang2)][docname] = [\n",
    "        line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        for line in open(f, \"r\")\n",
    "    ]\n",
    "\n",
    "cheatsheet = {\n",
    "    # inefficient but does not matter\n",
    "    tuple(line.split(\"\\t\")[0].replace(\"_\", \"-\", 1).split(\"_\")): json.loads(line.split(\"\\t\")[1].rstrip(\"\\n\").replace(\"'\", '\"'))\n",
    "    for line in open(\"/home/ec2-user/MetricsDomainAdaptation/data/shuoyang/cheat_sheet.txt\", \"r\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have a few new languages\n",
    "print(set([f\"{x}-{y}\" for x, y in data_all.keys()])-set(utils.LANGS2))\n",
    "print(set(utils.LANGS2)-set([f\"{x}-{y}\" for x, y in data_all.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang detect\n",
    "import langdetect\n",
    "\n",
    "for (lang1, lang2), data_docs  in data_all.items():\n",
    "    langs = lang1+\"-\"+lang2\n",
    "    for docname, doc in data_docs.items():\n",
    "        for _, _, line_src, line_tgt in doc:\n",
    "            try:\n",
    "                lang1_detected = langdetect.detect_langs(line_src)[0]\n",
    "                lang1_detected.lang = lang1_detected.lang.split(\"-\")[0]\n",
    "                if lang1 != lang1_detected.lang and lang1_detected.prob >= 0.9:\n",
    "                    print(langs+\":\"+docname, lang1, lang1_detected.lang, line_src)\n",
    "            except langdetect.LangDetectException:\n",
    "                print(\"Undetectable\", langs+\":\"+docname, line_src)\n",
    "            try:\n",
    "                lang2_detected = langdetect.detect_langs(line_tgt)[0]\n",
    "                lang2_detected.lang = lang2_detected.lang.split(\"-\")[0]\n",
    "                if lang2 != lang2_detected.lang and lang2_detected.prob >= 0.9:\n",
    "                    print(langs+\":\"+docname, lang2, lang2_detected.lang, line_tgt)\n",
    "            except langdetect.LangDetectException:\n",
    "                print(\"Undetectable\", langs+\":\"+docname, line_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# malformed segments\n",
    "re_sent_ok = re.compile(r\"^[\\w\\s\\d]*$\")\n",
    "\n",
    "for (lang1, lang2), data_docs  in data_all.items():\n",
    "    langs = lang1+\"-\"+lang2\n",
    "    for docname, doc in data_docs.items():\n",
    "        for _, _, line_src, line_tgt in doc:\n",
    "            # if not re_sent_ok.match(line_src):\n",
    "            if len([c for c in line_src if c.isalpha()]) <= 2:\n",
    "                print(langs+\":\"+docname, line_src)\n",
    "            if len([c for c in line_tgt if c.isalpha()]) <= 2:\n",
    "                print(langs+\":\"+docname, line_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = {}\n",
    "for (lang1, lang2), data_docs  in data_all.items():\n",
    "    langs = lang1+\"-\"+lang2\n",
    "    for docname, doc in data_docs.items():\n",
    "        cheatsheet_local = cheatsheet[(langs, \"doc\"+docname)]\n",
    "        for system, _, line_src, line_tgt in doc:\n",
    "            system = cheatsheet_local[int(system.removeprefix(\"system\"))]\n",
    "            line_hash = line_src + \" | \" + line_tgt\n",
    "            if line_hash in all_lines:\n",
    "                print(f\"{system}/{all_lines[line_hash]}\", line_hash)\n",
    "            else:\n",
    "                all_lines[line_hash] = system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "mt_models = {\n",
    "    (lang1, lang2): pipeline(\"translation\", model=f\"Helsinki-NLP/opus-mt-{lang1}-{lang2}\", device=0)\n",
    "    for lang1, lang2 in data_all.keys()\n",
    "    if len({lang1, lang2} & {\"pt\"}) == 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import tqdm\n",
    "\n",
    "def sent_overlap(a, b):\n",
    "    a = set(a.lower().split())\n",
    "    b = set(b.lower().split())\n",
    "    if len(a) <= 4 and len(b) <= 4:\n",
    "        return True\n",
    "    else:\n",
    "        # make sure there's some overlap\n",
    "        return (2*len(a & b))/(len(a)+len(b)) >= 0.15\n",
    "\n",
    "for (lang1, lang2), data_docs in tqdm.tqdm(list(data_all.items())):\n",
    "    langs = lang1+\"-\"+lang2\n",
    "    for docname, doc in data_docs.items():\n",
    "        for _, _, line_src, line_tgt in random.sample(doc, k=1):\n",
    "            if (lang1, lang2) in mt_models:\n",
    "                line_src_mt = mt_models[(lang1, lang2)](line_src)[0][\"translation_text\"]\n",
    "                if not sent_overlap(line_src_mt, line_tgt):\n",
    "                    print(langs+\":\"+docname, line_src_mt, line_tgt)\n",
    "            if (lang2, lang1) in mt_models:\n",
    "                line_tgt_mt = mt_models[(lang2, lang1)](line_tgt)[0][\"translation_text\"]\n",
    "                if not sent_overlap(line_tgt_mt, line_src):\n",
    "                    print(langs+\":\"+docname, line_tgt_mt, line_src)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
